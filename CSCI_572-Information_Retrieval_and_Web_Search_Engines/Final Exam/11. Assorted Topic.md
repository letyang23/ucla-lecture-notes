# Assorted topics: Part 1

### IR - keeps evolving...

As with everything else, the field of information retrieval keeps changing - there are newer forms of data, newer algorithms, cross-pollination from other fields...

In this lecture and the next, we take a BRIEF look at a variety of developments. 'BRIEF' because each topic (eg. vector DBs) is a detailed area, we simply can't cover all of them in any detail. In other words, you can look into what interests you, later (after the course ends).

The following topics are grouped where possible, but are otherwise in no particular order.

### Image understanding and search

[ImageNet](https://image-net.org/) is a massive DB, of human-annotated images.

It can serve as a vehicle to drive ML algorithms (eg. CNN, VT): https://www.youtube.com/watch?v=40riCqvRoMs

You can learn more [here.](https://bytes.usc.edu/cs572/s25-555-sear-ch/lectures/Misc1/docs/ImageSearch.pdf)

### Code search

GitHub does code search this way: https://github.blog/2023-02-06-the-technology-behind-githubs-new-code-search/ [and https://github.com/features/copilot].

[Here](https://bytes.usc.edu/cs572/s25-555-sear-ch/lectures/Misc1/docs/ProgWithCopilot_6tfVV.pdf) is how you can use Copilot :)

### LBS/PS

Location Based Search (LBS), ie. Proximity Search (PS), is about using location data where the query originates, and using that to return responses.

Here is an intro: https://www.businessnewsdaily.com/5386-location-based-services.html

https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8399432/ presents an efficient way to do LBS.

LBS can be exploited, to find (track) a user precisely: https://www.cs.uic.edu/~polakis/tr/proximity-tr.pdf

### Similarity search using vector DBs

Pinecone is a NEW type of DB called 'vector DB', which embeds into vector (XYZ...) orthogonal space, the items (data) we want to search for (using 'cosine similarity'!). [Here](https://www.pinecone.io/learn/what-is-similarity-search/) is a primer.

We can also use vector DBs as 'infinite memory', to create generative tools, eg. a [semantic search engine.](https://bytes.usc.edu/cs572/s25-555-sear-ch/lectures/Misc1/docs/towardsdatascience-how-to-easily-deploy-a-local-generative-search-engine-using-verifai-cdf9dedf53c0-2025-05-01-13_02_20.pdf)

### LDA, for topic modeling

Given a document, how to predict its dominant topic(s)? [Here](https://bytes.usc.edu/cs572/s25-555-sear-ch/lectures/Misc1/docs/medium-how-to-build-a-lda-topic-model-using-from-text-601cdcbfd3a6-2025-05-01-13_08_33.pdf) is one approach.

### ANN (Faiss)

Approximate Nearest Neighbor calcs are much faster than exact ones. [Here](https://bytes.usc.edu/cs572/s25-555-sear-ch/lectures/Misc1/docs/towardsdatascience-comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6-2025-05-01-13_24_16.pdf) is more.

### Task-specific fine-tuning

'Fine-tuning' is the concept of adapting a general-purpose model, for a specific purpose. The following is an account of GPT-2 was fine-tuned to generate scientific paper abstracts:
![img](11. Assorted Topic.assets/Finetuning_GPT2_4wsd.png)

### Task-specific embedding

Multiple NLP tasks can be handled by a system, if it embeds a document in a way that's related to the task: https://pub.towardsai.net/paper-review-instructor-one-embedder-any-task-6a846b0d3ba





# Assorted topics: Part 2 ["there's MORE!"]

### The roundup continues...

We continue looking at even more 'cutting edge' technologies, and industry implementations - of retrieval, recommendations, knowledge extraction, etc.

This much is for sure - the field of 'IR' is one of the most RAPIDLY changing fields! Why? Because **information** is what runs society :)

### External memory to enhance generic chat

The idea of using an LLM as a generic text engine (that has no deep 'domain knowledge) ALONG WITH 'external memory' [a custom 'DB' that contains content knowledge] is rapidly gaining ground!

https://towardsdatascience.com/use-chatgpt-to-query-your-neo4j-database-78680a05ec2 shows how ChatGPT can be used with Neo4j (a graph DB). The idea is this: rather than query Neo4j using its own 'Cypher' query language, we can use natural language instead.

https://tdoehmen.github.io/blog/2023/03/07/quackingduck.html shows to use chat to generate SQL!

RR - Rethinking with Retrieval (https://arxiv.org/pdf/2301.00303) solves reasoning-based tasks by using an external KB (knowledge base).

'Retrieval Transformer' is an approach that also uses external memory to keep the core LLM size DOWN [as low as 4%!!] of a regular LLM - https://jalammar.github.io/illustrated-retrieval-transformer/.

### Autonomous task-achieving

Rather than carry on a back-and-forth conversation with an LLM to achieve a task, what if we could specify the task, and let the LLM AUTONOMOUSLY solve it, using sub-goals? This is classic 'agent-based' architecture, an elusive idea in AI thus far!

AutoGPT [eg. https://www.digitaltrends.com/computing/what-is-auto-gpt/] is a brand new approach that does this.

Another radical idea is use LLMs to simulate human behavior, giving rise to 'generative agents': https://arxiv.org/abs/2304.03442.

### LLM+tasks+memory -> a 'computer' system!

Here is yet another idea: treat the LLM+tasks+DB as a 'computer' (analogous to processor+code+data)!

BabyAGI [eg. https://finance.yahoo.com/news/babyagi-taking-silicon-valley-storm-121500747.html] is such an attempt.

LangChain is a task programming language where we use specific commands in the form of 'templates', to compose our queries, and run() them, eg. https://www.pinecone.io/learn/langchain-intro. [SudoLang](https://bytes.usc.edu/cs572/s25-555-sear-ch/lectures/Misc2/docs/medium.com-SudoLangAPowerfulPseudocodeProgrammingLanguageforLLMs.pdf) is another such task-spec language.

'OPL' is the name we could give to such a stack comprised of O(penAI)+P(inecone)+L(angChain), eg. https://towardsdatascience.com/building-llms-powered-apps-with-opl-stack-c1d31b17110f

Also :)
![img](11. Assorted Topic.assets/meetup.png)

### NER

'NER' (Named Entity Recognition) as you know, is a useful NLP information-related task - given text, or images, or video, or audio, what person/place/thing/... can we identify?

We can use [BERT for NER](https://bytes.usc.edu/cs572/s25-555-sear-ch/lectures/Misc2/docs/BERT_NER.pdf), eg. via PyTorch.

### Topic modeling

[BERTopic](https://arxiv.org/pdf/2203.05794) is a topic-modeling technique based on [BERT.](https://www.techtarget.com/searchenterpriseai/definition/BERT-language-model)

[Here](https://medium.com/@nick-tan/topic-modeling-with-bertopic-a-cookbook-with-an-end-to-end-example-part-1-3ef739b8d9f8) is a guide.

### KG construction

Knowledge graphs (KGs) are an excellent form of knowledge representation, since they are well structured (eg via (s,p,o) triplets). https://medium.com/@dallemang/llms-closing-the-kg-gap-29feee9fa52c shows how we can use ChatGPT to create KGs from plain (ie unstructured text).

### Recommendation engines

REs are univerally useful, across multiple domains.

Monolith is TikTok's RE: https://analyticsindiamag.com/tiktok-parent-bytedance-reveals-its-sota-recommendation-engine/.

Twitter's RE:
![img](11. Assorted Topic.assets/Twitter_ForYou.png)

Lyft's RE: https://eng.lyft.com/the-recommendation-system-at-lyft-67bc9dcc1793.

### Clustering

We looked at K-means clustering. Here are others you can look up:

- t-SNE, eg. https://towardsdatascience.com/t-sne-clearly-explained-d84c537f53a
- HDBSCAN, eg. https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html
- UMAP, eg. https://umap-learn.readthedocs.io/en/latest/clustering.html

### Search

Here is an assortment of 'search' related items:

- [this](https://opensource.com/article/23/4/search-engine-creative-commons-openverse) search looks for CC (Creative Commons) licensed content (images, audio)
- 'manifold search' uses manifold learning for similarity searches, eg. https://scikit-learn.org/stable/modules/manifold.html
- NN searches over a graph (rather than metric space): https://research.yandex.com/blog/graph-based-nearest-neighbor-search
- Redis-based AI-driven (vector) search: https://partee.io/notes/2022-9-13-SDSC-talk/
- Discord search (using inverted indexing): https://sukhadanand.medium.com/how-discord-indexes-billions-of-messages-f242e605e47c

### NeRF, AR LBS

[Standard](https://www.google.com/search?q=starbucks+near+me&rlz=1C1CHBF_enUS723US723&oq=starbucks+&aqs=chrome.3.69i57j0i433i512j0i512j0i433i457i512j0i402i650l2j0i512j69i61.5318j0j7&sourceid=chrome&ie=UTF-8) LBS retrieves addresses, maps.

A new Google Maps update will retrieve [immersive views](https://blog.google/products/maps/three-maps-updates-io-2022/), made possible by fusing together numerous distinct photos and aerial views, and seamlessly rendering them using [NeRF](https://datagen.tech/guides/synthetic-data/neural-radiance-field-nerf/) [more [here](https://www.cnet.com/tech/services-and-software/google-maps-new-feature-lets-you-visit-restaurants-from-home/)].



# Assorted topicsPart 3 ["there's EVEN MORE!"]

### Attention!!!

![img](11. Assorted Topic.assets/Transf-4edG.png)

"A Transformer computes self-attention."

- Jay Alammar: https://jalammar.github.io/illustrated-transformer/ and https://github.com/HandsOnLLM/Hands-On-Large-Language-Models
- [Yule Wang: medium.com-Step-by-Step Illustrated Explanations of Transformer.pdf](https://bytes.usc.edu/cs572/s25-555-sear-ch/lectures/Misc3/docs/medium.com-Step-by-Step Illustrated Explanations of Transformer.pdf)
- Stephen Wolfram: https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/
- Damien Benveniste: https://learn.theaiedge.io/p/introduction-to-transformers-for-large-large-models and https://betterprogramming.pub/chatgpt-llms-and-foundation-models-a-closer-look-into-the-hype-and-implications-for-startups-b2f1d82f4d46#86bb
- Stefania: https://machinelearningmastery.com/the-transformer-attention-mechanism/
- Vinija: https://vinija.ai/models/LLM/#google_vignette
- https://www.youtube.com/watch?v=NzLwHcqE6Jw [The animated Transformer: the Transformer model explained the fun way!]
- https://www.marktechpost.com/2024/08/13/transformer-explainer-an-innovative-web-based-tool-for-interactive-learning-and-visualization-of-complex-ai-models-for-non-experts/ and https://poloclub.github.io/transformer-explainer/

Transformers can be adapted to other domains, eg. ViT [https://www.linkedin.com/pulse/vision-transformer-damien-benveniste-phd-nygoc], time-series prediction, music gen, etc.

One form of training data (JSONL - JSON Lines): https://huggingface.co/datasets/databricks/databricks-dolly-15k and https://huggingface.co/datasets/databricks/databricks-dolly-15k/tree/main [databricks-dolly-15k.jsonl]

[Here](https://bytes.usc.edu/cs572/s25-555-sear-ch/lectures/Misc3/docs/DataBricks_ACompactGuideToLLMs.pdf) is a lightweight intro to LLMs.

### Context

Because 'context is everything', we need to address the 'quadratic bottleneck' of attention computation. Here are ways:

![img](11. Assorted Topic.assets/hyena-ops.png)

![img](11. Assorted Topic.assets/mamba-45esx.png)

![img](11. Assorted Topic.assets/Infini-attention.png)

NV's Hymba is a 'mixed' architecture meant for small models - to help them capture context efficiently.

### PFFFFF-FT!!

A way to augment an LLM's general learning, is to 'fine tune' [(FT)](https://www.databricks.com/blog/efficient-fine-tuning-lora-guide-llms) it for specialized domains such as medicine, law, etc.

ReFT is the latest FT technique:
![img](11. Assorted Topic.assets/REFT_vs_PEFT.png)

Here is a comprehensive list of FT techniques: https://arxiv.org/pdf/2408.13296

### RAGGGG-GG

Another way to augment a query's context (in addition to finetuning) is to use external (to LLMs) memory - in the form of vector DBs, KGs, classical (relational) DBs, etc. 'Hybrid RAG' combines multiple RAGs (most commonly, vector DBs and KGs).

But there can be 'issues' with RAG too - context mismatch, incorrectly chunked input [for vectorizing]...

Eg. EyeLevel is a company that offers RAG as an API [called GroundX]: https://www.eyelevel.ai/post/most-accurate-rag and https://www.eyelevel.ai/post/do-vector-databases-lose-accuracy-at-scale
![img](11. Assorted Topic.assets/EyeLevel_XRay_5rffgL.png)
![img](11. Assorted Topic.assets/EyeLevel_AF_KLM_jh5rE.png)

Here is a long article on doing RAG well: https://arxiv.org/pdf/2409.14924.

HyDE - "RAG++" :)

### GenAI

GANs start out as a pair of 'adversarial' networks - the 'student' one gets VERY good at **content generation**!!!

VAEs do likewise.

GPT: **Generative** [token generation] Pretrained Transformer.

Today we have variations - generation via diffusion, generation via radiance modeling, generation via point-cloud modeling, generation via musical pattern modeling...

Almost ANYTHING can be generated - molecular representations, architectural plans, circuit layout, business cards, A/V/I/3D, etc etc.

### New directions

As is to be expected, the wild new world of LLMs began with 'ChatGPT' in Nov'22 - but is expanding in multiple, very interesting directions!

Here is an assorted list of LLM-related growth areas:

- hardware
- non-Transfomer alts, eg. https://towardsdatascience.com/attention-is-not-all-you-need-ef7b6956d425 and SSMs [Mamba, Hyena, and also, Jamba, Hymba!], and [Diffusion Models](https://medium.com/@roelljr/the-ultimate-guide-rnns-vs-transformers-vs-diffusion-models-5e841a8184f3)
- alternative position encodings, eg RoPE: https://www.modular.com/ai-resources/rotary-position-embedding-rope
- SLMs [tons over at https://huggingface.co/models etc.]
- VLMs, FMs, NatureLMs, DataLM, https://github.com/adlnlp/FinLLMs, *Ms in general
- bit-crushed weights [incl this update: https://arxiv.org/abs/2504.18415 [that uses image processing's [Hadamard](https://www.google.com/search?q=image+processing+Hadamard+transformation&rlz=1C1RXQR_enUS1047US1047&oq=image+processing+Hadamard+transformation&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRiPAtIBCTE0MzIzajBqMagCALACAQ&sourceid=chrome&ie=UTF-8) transform]
- multimodal LLMs [text, image, audio, video]
- 'embodied' LLMs
- agentic approaches - involve 'reasoning', tool use, MoE, CoT, ToT, GoT... Here is a HUGE list of agent-related topics: https://github.com/NirDiamant/GenAI_Agents, https://github.com/dynamiq-ai/dynamiq [and https://www.getdynamiq.ai/]
- local running of LLMs
- MCC, APIs [eg. 'NIM': https://nvidianews.nvidia.com/news/generative-ai-microservices-for-developers, https://www.nvidia.com/en-us/ai/?videogallery=mg0kwpmUhPU]
- programming language APIs (eg Dart SDK for Gemini, eg. https://youtu.be/lpnKWK-KEYs?t=473) and SQL, eg. https://www.databricks.com/blog/2023/04/18/introducing-ai-functions-integrating-large-language-models-databricks-sql.html
- visual dataflow envs for app dev, eg. ComfyUI, LangFlow, etc.
- PO: incl GRPO, TTRL, RLVR
- standards: DSPy, A2A, MCP...

### LLM apps

Apps BASED ON (that make use of) LLMs offer lots of promise, including new uses/architectures we haven't thought of yet.

Here is a growing list: https://github.com/Shubhamsaboo/awesome-llm-apps

Fin-GPT: https://huggingface.co/FinGPT and https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/

NotebookLM: https://notebooklm.google/

[Here](https://bytes.usc.edu/cs572/s25-555-sear-ch/lectures/Misc3/docs/DataBricks_GenAIArchsInclRAG.pdf) is a guide that describes DataBricks' approach/architecture for enabling GenAI apps on their platform.

### LLM Ops!

Productionizing LLM apps need extra steps and processes... Here is a growing list: https://github.com/SylphAI-Inc/LLM-engineer-handbook

An article on AI Engineering: https://www.newsletter.swirlai.com/p/what-is-ai-engineering

A growing db: https://www.zenml.io/llmops-database

### Agentic IR (aka 'AIR' :))

https://arxiv.org/pdf/2410.09713 - what if ALL of IR becomes semantics+agents based?